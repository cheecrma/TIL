### 합성곱 신경망(Convolution Neural Network)

이미지 처리에 탁월한 성능을 보이는 신경망

- 합성곱층(Convolution layer)

- 풀링층(Pooling layer)

CONV는 합성곱 연산을 의미하고, 합성곱 연산의 결과가 활성화 함수 ReLU를 지남.

이 두 과정을 합성곱층이라고 함.

그 후에 POOL이라는 구간을 지나는데 이는 풀링 연산을 의미하며 풀링층이라고 함.

---

### 합성곱 신경망의 대두

이미지 처리를 하기 위해서 다층 퍼셉트론을 사용할 수는 있지만 한계가 있음.

- 다층 퍼셉트론은 몇 가지 픽셀만 값이 달라져도 민감하게 예측에 영향을 받음.
  
  - 다층 퍼셉트론으로 분류한다고 하면, 이미지를 1차원 텐서인 벡터로 변환하고 다층 퍼셉트론의 입력층으로 사용해야 함.
  
  - 1차원으로 변환된 결과는 변환 전에 가지고 있던 공간적인 구조(spatial structure)정보가 유실된 상태
    
    - 여기서 공간적인 구조 정보라는 것은 거리가 가까운 어던 픽셀들끼리는 어떤 연관이 있고, 어떤 픽셀들끼리는 값이 비슷하거나 등을 포함하고 있음.
    
    - 결국 이미지의 공간적인 구조 정보를 보존하면서 학습할 수 있는 방법이 필요해졌고, 이를 위해 합성곱 신경망을 사용함.

---

### 채널 (Channel)

기계는 글자나 이미지보다 숫자. 다시 말해, 텐서를 더 잘 처리할 수 있음.

이미지는 (높이, 너비, 채널)이라는 3차원 텐서임.

여기서 높이는 이미지의 세로 방향 픽셀 수, 너비는 이미지의 가로 방향 픽셀 수, 채널은 색 성분을 의미함.

흑백 이미지는 채널 수가 1이며, 각 픽셀은 0부터 255 사이의 값을 가짐.

채널은 때로는 깊이(depth)라고도 함.

---

### 합성곱 연산 (Convolution operation)

합성곱층은 합성곱 연산을 통해서 이미지의 특징을 추출하는 역할.

합성곱은 커널(kernel) 또는 필터(filter)라는 n x m 크기의 행렬로 높이 x 너비 크기의 이미지를 처음부터 끝까지 겹치며 훑으면서 n x m 크기의 겹쳐지는 부분의 각 이미지와 커널의 원소의 값을 곱해서 모두 더한 값을 출력으로 하는 것을 말함.

이 때, 이미지의 가장 왼쪽 위부터 가장 오른쪽 아래까지 순차적으로 훑음.

- 커널(kernel)은 일반적으로 3 x 3 또는 5 x 5를 사용함.

- 커널을 사용하여 합성곱 연산을 통해 나온 결과를 특성 맵(feature map)이라고 함.

- 커널의 이동 범위를 스트라이드(stride)라고 함.

- 커널의 크기와 이동 범위는 사용자가 정할 수 있음.

---

### 패딩 (Padding)

합성곱 연산 이후에도 특성 맵의 크기가 입력의 크기와 동일하게 유지되도록 하고 싶다면 패딩을 사용하면 됨.

패딩은 (합성곱 연산을 하기 전에)입력의 가장자리에 지정된 개수의 폭만큼 행과 열을 추가해주는 것을 말함.

주로 값을 0으로 채우는 제로 패딩(zero padding)을 사용 함.

만약 스트라이드가 1이라고 하였을 때, 3 x 3 크기의 커널을 사용한다면 1폭짜리 제로 패딩을 사용하고, 5 x 5 크기의 커널을 사용한다면 2폭 짜리 제로 패딩을 사용하면 입력과 특성 맵의 크기를 보존할 수 있음.

---

### 가중치와 편향

1. 합성곱 신경망의 가중치
   
   합성곱 신경망에서 가중치는 커널 행렬의 원소들.
   
   각 합성곱 연산마다 이미지의 모든 픽셀을 사용하는 것이 아니라, 커널과 맵핑되는 픽셀만을 입력으로 사용함.
   
   결국 합성곱 신경망은 다층 퍼셉트론을 사용할 때보다 훨씬 적은 수의 가중치를 사용하며 공간적 구조 정보를 보존한다는 특징이 있음.
   
   - 합성곱 연산을 통해 얻은 특성 맵은 다층 퍼셉트론때와 마찬가지로 비선형성 추가를 위해서 활성화 함수를 지나게 됨. 이때 렐루 함수나 렐루 함수의 변형들이 주로 사용 됨.
   
   - 합성곱 연산을 통해서 특성 맵을 얻고, 활성화 함수를 지나는 연산을 하는 합성곱 신경망의 층을 합성곱 신경망에서는 합성곱 층 (Convolution layer)이라고 함.

2. 합성곱 신경망의 편향
   
   합성곱 신경망에도 편향(bias)를 당연히 추가할 수 있음. 만약, 편향을 사용한다면 커널을 적용한 뒤에 더해짐.
   
   편향은 하나의 값만 존재하며, 커널이 적용된 결과의 모든 원소에 더해짐.

---

### 특성 맵의 크기 계산 방법

입력의 크기와 커널의 크기, 그리고 스트라이드의 값만 알면 합성곱 연산의 결과인 특성 맵의 크기를 계산할 수 있음.

---

### 다수의 채널을 가질 경우의 합성곱 연산 (3차원 텐서의 합성곱 연산)

입력 데이터의 채널 수와 커널의 채널 수는 같아야 함.

---

### 3차원 텐서의 합성곱 연산

합성곱 연산에서 다수의 커널을 사용할 경우, 사용한 커널 수는 합성곱 연산의 결과로 나오는 특성 맵의 채널 수가 됨.

---

### 풀링 (Pooling)

합성곱 층(합성곱 연산 + 활성화 함수) 다음에는 풀링 층을 추가하는 것이 일반적임.

풀링 연산은 커널과 스트라이드 개념이 존재한다는 점에서 합성곱 연산과 유사하지만, 합성곱 연산과의 차이점은 학습해야 할 가중치가 없으며 연산 후에 채널 수가 변하지 않는다는 점.










