### 이미지를 설명하는 문장을 만들어내는 Image Captioning

Fully conn에 RNN을 이어붙여 만들었던 최초의 IC 논문이 Show and Tell 인데 이전 단어 들이 주어졌을 때, 다음 단어의 확률 분포와 같음. 이전 단어들이 나왔을 때, 해당 단어가 나올 조건부 확률임을 확인할 수 있음. 하지만 잘되진 않았음.

다음 논문인, Show, Attend and Tell이 있음. 여기서 Attention은 내가 지금 주어진 이미지 안에서 어느 영역을 보고 지금 단어를 만들지에 대한 것임.

Show and tell과 Show, Attend and tell의 구조적인 차이는, 전자는 CNN의 Fully conn 출력을 LSTM에 넣었던 것에 비해, 후자는 CNN의 Conv feature map을 통해 Attention을 구현한 후 LSTM에 넣었다는 점. Conv feature map을 사용함으로써 Spatial한 정보를 잃지 않았던 거.

다음으로 DenseCap이 있음.
