### 인공신경망 - Artificial Neural Networks

1943년 신경생리학자 Warren McCulloch과 수학자 Walter Pitts가 "A Logical Calculus of Ideas Immanent In Nervous Activity" 처음 소개했으며, 명제 논리(propositional logic)를 사용해 동물 뇌의 생물학적 뉴런이 복잡한 계산을 위해 어떻게 상호작용하는지에 대해 간단한 계산 모델을 제시했음.

---

1960년대까지는 이렇게 등장한 인공 신경망을 통해 사람들은 지능을 가진 기계와 대화를 나눌 수 있을 것이라고 생각.

하지만 사람들의 기대와는 달리 인공 신경망으로 XOR 문제를 해결할 수 없게 되었고, 1990년 대에는 SVM과 성능이 좋은 다른 머신러닝 알고리즘들이 나오게 되면서 인공 신경망은 암흑기로 접어 들게 되었음.

---

2000년 대에 들어서면서 인공 신경망은 2012년 ILSVRC2012 대회에서 인공 신경망을 깊게 쌓은 딥러닝 모델인 AlexNet이 압도적인 성적으로 우승하면서 다시금 주목받게 되었음.

이렇게 인공 신경망(딥러닝)이 다시 주목받게 된 계기는 다음과 같은 것들이 있음.

- 빅 데이터 시대인 요즘 신경망을 학습시키기 위한 데이터가 엄청나게 많아 졌음.

- 신경망은 다른 머신러닝 알고리즘보다 규모가 크고 복잡한 문제에서 성능이 좋음.

- 1990년대 이후 크게 발전된 컴퓨터 하드웨어 성능과 Matrix 연산에 고성능인 GPU로 인해 상대적으로 짧은 시간 안에 대규모의 신경망을 학습시킬 수 있게 되었음.

---

### 뉴런

- 생물학적 뉴런
  
  - Dendrite : 수상돌기, 다른 뉴런으로부터 신호를 수용하는 부분
  
  - Axon : 축삭돌기, 신호를 내보내는 부분
  
  - Synaptic terminals : 시냅스(synapse) 뉴런의 접합부, 다른 뉴런으로 부터 짧은 전기 자극 신호(signal)를 받음

- 최초의 인공 뉴런
  
  - 처음 인공 신경망을 제안한 Warren McCulloch과 Walter Pitts의 인공 뉴런 모델은 하나 이상의 이진(on/off) 입력과 하나의 출력을 가진다.

### 퍼셉트론

- Frank Rosenblatt가 1975년에 제안한 인공 신경망 구조 중 하나이며, 이 퍼셉트론이 바로 신경망(딥러닝)의 기원이 되는 알고리즘이라고 할 수 있음.

- 퍼셉트론은 TLU(Threshold Logic Unit)이라는 형태의 뉴런을 기반으로 하며, 아래의 그림과 같이 입력과 출력이 어떤 숫자고 각각의 입력에 각각 고유한 가중치가 곱해짐. 그런 다음 계산된 합에 계단 함수(step function)를 적용하여 결과를 출력 함.

- 퍼셉트론에서 가장 널리 사용되는 계단 함수는 헤비사이드 계단 함수(Heaviside step function)이며, 단위 계단 함수(unit step function)라고도 함.

- 간혹 게단 함수 대신 부호 함수(sign function)를 사용하기도 함.

- 퍼셉트론 학습
  
  - Frank Rosenblatt가 제안한 퍼셉트론의 학습 알고리즘은 헤브의 규칙(Hebb's rule)로 부터 영감을 받음.
  
  - Donald Hebb는 1949년에 출간한 책 'The Organization of Behavior'에서 뉴런이 다른 뉴런을 활성화시킬 때 이 두 뉴런의 연결이 강해진다고 주장.
  
  - 즉, 두 뉴런이 동일한 출력을 낼 때마다 이 둘 사이의 연결 가중치가 증가하며 이러한 규칙을 헤브의 규칙 또는 헤브 학습(Hebbian Learning)이라고 함.
  
  - 퍼셉트론은 네트워크가 만드는 에러를 반영하도록 학습되며 잘못된 출력을 만드는 연결은 올바른 출력을 만들 수 있도록 가중치를 조정함.
  
  - Frank Rosenblatt는 학습 데이터가 선형적으로 구분될 수 있으면, 퍼셉트론은 정답에 수렴한다는 것을 보였는데 이를 퍼셉트론 수렴 이론(Perceptron convergence theorem)이라 함. 하지만, 출력 뉴런의 decision boundary는 선형(결합)이므로 퍼셉트론은 복잡한 패턴 (e.g. 비선형)은 학습하지 못함.

- Scikit-Learn의 Perceptron 클래스
  
  - 하나의 TLU 퍼셉트론을 구현한 Perceptron 클래스를 제공함.

- 퍼셉트론의 약점 : XOR 문제
  
  - 1969년 Marvin Minsky와 Seymour Papert는 '퍼셉트론'이란 논문에서 퍼셉트론의 심각한 약점이 있다는 것을 보였는데 그 중에서도 가장 결정적인 것은 선형결합인 퍼셉트론이 배타적 논리합인 XOR 분류 문제를 해결할 수 없다는 것이었음. 이를 계기로 인공 신경망은 암흑기를 맞이하게 됨. 하지만, 단일 퍼셉트론을 여러 개 쌓아 다층 퍼셉트론(MLP, Multi-Layer Perceptron)을 통해 XOR분류 문제를 해결할 수 있었음.

- 다층 퍼셉트론과 역전파
  
  - 다층 퍼셉트론(MLP)은 아래의 그림과 같이 입력층, 은닉층(hidden layer)이라 부르는 하나 이상의 TLU 층과 마지막으로 출력층(output layer)으로 구성됨.
  
  - 인공 신경망의 은닉층이 2개 이상일 때, 심층 신경망(DNN, Deep Neural Network)라 하고 이를 학습하여 모델을 만드는 것을 우리가 익히 들어온 딥러닝(Deep -Learning)이라고 함.
  
  - 이렇게 여러층을 쌓은 MLP를 통해 XOR 문제를 해결 했지만, 층이 깊어질 수록 증가하는 가중치 매개변수의 수로 인해 다층 퍼셉트론을 학습시키기에는 오랜 시간이 걸리는 문제가 발생.
  
  - 하지만, 1986년 역전파(backpropogation) 알고리즘이 등장하면서 계산량을 획기적으로 줄일 수 있게 되었음.
  
  - 역전파법 간단히 확인
    
    1. 각 학습 데이터 샘플을 네트워크에 입력으로 넣어주고 출력층까지 각 층의 뉴런 마다 출력을 계산함. 이를 순전파(forward propagation)이라고 함.
    
    2. 그 다음 네트워크의 마지막 출력층에 대한 결과(예측값)와 실제값과의 차이, 즉 오차(error)를 계산하는데, 손실함수(loss function)를 이용하여 계산함.
    
    3. 그리고 이 오차를 역방향으로 흘러 보내면서, 각 출력 뉴런의 오차에 마지막 입력 뉴런이 얼마나 기여했는지 측정. (각 뉴런의 입력값에 대한 손실함수의 편미분, 그래디언트(gradient)을 계산하는 것)
    
    4. 3번과 같은 방법을 입력층에 도달할 때까지 계속 반복해서 역방향으로 흘러보냄.
    
    5. 마지막으로, 계산한 그래디언트를 네트워크의 모든 가중치 매개변수에 반영해주는 경사 하강법 단계를 수행함.
  
  - 따라서, 먼저 순전파를 통해 네트워크가 예측을 출력(출력층의 출력 결과)하고, 이를 손실함수를 이요해 오차를 계산한 뒤, 역방향으로 거슬러 올라가면서 각 뉴런의 입력값에 대한 손실함수의 편미분을 계산하고(backpropagation), 이를 경사 하강법을 이용해 가중치를 조정하는 방법이 역전파 알고리즘.

- 활성화 함수(activation function)
  
  - 역전파 알고리즘이 잘 동작하기 위해서 다층 퍼셉트론(MLP)의 구조에 변화를 주었는 데, 그것이 바로 활성화 함수 부분에서 계단 함수를 시그모이드 함수(로지스틱 함수)로 바꿔준 것.

- 소프트맥스(softmax) 함수
  
  - 출력층에서 주로 사용하는 활성화 함수임.
  
  - 소프트맥스 함수의 특징은 출력값의 총합이 1이 됨. 따라서, 각 출력 뉴런에 대한 소프트맥스의 출력값은 각 클래스에 대응하는 추정 확률값으로 볼 수 있음.

### tf.estimator를 이용한 DNN 구현

- 텐서플로는 사용자가 쉽게 신경망 모델링을 프로그래밍할 수 있도록 high-level의 API를 제공함. 대표적인 high-level API로는 tf.estimator 와 keras가 있음.






