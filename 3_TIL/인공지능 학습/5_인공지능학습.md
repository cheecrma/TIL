기존 이미지 캡셔닝의 문제점 - Attention의 등장

- Spoiler: 요즘 유행하는 Transformer에 나오는 그 Attention 맞음.

- 상대적인 관계나 공간 위치가 고려되지 않음

- Global average pooling 같은 과정에서 작은 사물들이 무시되는 경향이 있음.

- 문장이 생성이 될 때 어떤 것을 보고 판별한 것인지 해석이 되지 않을 때가 있음.

---

Show, attend and tell

1. 입력 이미지

2. CNN모델로 Feature 추출

3. RNN을 통한 각 스텝의 Attention 위치 추론

4. 단어 단위로 생성

---

Visual Attention

- Global vector 대신 공간 정보를 가지고 있는 중간 레이어에서 특징 V 추출

- V는 Attention의 후보들이 됨
  
  (feature vector 들은 이미지의 서로 다른 부분들에서 추출된 것)

---

Attention으로 image captioning 하는 방법

- Show, attend, and tell - Inference

---

최근 발전 동향 GPT-3

- GPT-3 예시: 낚시성 기사 제목 쓰기

- DALL-E

---

Transformer - Attention is all you need

- Transformer 모델이란?
  
  - Self-attention 레이어를 적층해서 조립한 모델
  
  - 다양한 자연어처리 테스크를 하나의 모델로 모두 해결
  
  - GPT-3: Transformer 기반 총 1750억 개의 Parameter 사용

- Self-attention 레이어란?
  
  - 하나의 Input데이터에서 Query와 Key를 통해 Attention weights를 그리고 Value feature를 통해 Output을 뽑음.

- Multi-head attention
  
  - 다양한 관계성 학습에 유리

---

자연어 처리 인공지능의 파급력

- 잘못 사용되면 위험할 수 있음

- 인공지능이 작성한 기사 등.

---

Sound representation

- 전통적 음향 특징 추출법

- 퓨리에 변환
  
  - 입력 신호의 각 주파수의 정현파가 얼만큼 포함되어 있는지 분석하는 기법
  
  - Sort-time Fourier transform (STFT)
    
    - 짧은 구간의 윈도우  내에서 퓨리에 변환을 하믕로써 단시간의 주파수 특성을 분석하는 방법

- 스펙트로그램
  
  - 각 짧은 윈도우에서 추출된 스펙트럼을 시간 축으로 쌓은 것
  
  - 대부분은 음성 관련 인공지능 모듈의 입력과 출력으로 흔히 사용되는 표현

---

Applicationo - joint embedding

- Scene recognition by sound

Spectrogram to waveform?

- 스팩트로그램에서 다시 재생가능한 Waveform으로 완벽하게 복원 할 수 있을까?
  
  - 쉽지 않음.
  
  - Vocoder
    
    - 스펙트로그램에서 waveform으로 변환을 근사해주는 모듈
    
    - WaveNet Vocoder
      
      - Large receptive field 1D CNN with gated activation

Text to Speech(TTS)

- Text => Mel-Spectrogram => 1D waveform

Application - Speech2Face

- 수화기 건너편에 있는 사람의 얼굴을 목소리로부터 상상할 수 있을까?

Application - Speech separation

- Speech separation: Looking to listen at the cocktail party

Application - Face animating by speech

- Lip motion generation from speech


