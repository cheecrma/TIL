#### Multi-modal learning

어려운 부분

- 서로 다른 데이터 타입 간 다른 데이터 표현 방식

- 서로 다른 데이터 타입 간 가지고 있는 정보의 비대칭 관계

---

Text embedding

- 문자열 표현은 인공지능 모델들이 사용하기에 어려움 Dense vector로 치환하여 사용 (Code화)

- 의미를 포함하여 코드화 => 높은 일반화 능력 (의도한 것은 아님)
  
  - 남자와 여자 차이의 벡터가 킹과 퀸의 벡터랑 같음.

- Word2vec: skip-gram 모델
  
  - W와 W ' 을 입력 단어에 대해서 문장 주변에 나올 것 같은 단어를 예측하게 학습
  
  - W의 각 행이 각 단어의 embedding vector로 학습됨
  
  - 주어진 단어에 대해서 N 개의 이웃 단어를 예측하도록 학습 => 단어간 관계성 학습
    
    - ex: Window size 5 인 경우 이웃한 4개의 단어들과의 관계 이용

Application - Image-tagging

- 영상과 단어간 Joint embedding을 학습하여 구현 가능
  
  - 영상이 주어지면 영상에 연관된 테그 자동 생성 가능
  
  - 테그가 주어지면 연관된 영상 검색 가능

- 미리 학습된 각 유니모달 모델들을 합성

- 학습 기법: 대응하는 영상과 단어는 유사하게, 상관 없는 단어와 영상은 멀어지게

- 의도하지 않았지만 자연스럽게 유사관계를 이해

- 다른 응용 사례
  
  - 영상 - 레시피 검색

Cross-modal translation

- 영상 => 텍스트: 이미지 캡셔닝
  
  - 영상 분석을 위한 CNN과 문장 생성을 위한 RNN의 결합

Recurrent Neural Network (RNN)

- RNN = 피드백 + 재활용

---

모델의 형태에 따른 쓰임새

- one to one
  
  - "standard"분류 모델 / 회귀(regression) 문제

- one to many
  
  - 이미지 캡션(이미지만 보고 설명하는 모델)

- many to one
  
  - 문장 분류기, 객관식 문제 풀이모델

- many to many
  
  - 번역기, 비디오 분류, 비디오 캡션

---

주로 사용되는 RNN의 종류

- Long short-term memory (LSTM)
  
  - Since 1997
  
  - Forget gates
  
  - vanishing/exploding gradient 이슈 완화

- Gated recurrent unit (GRU)
  
  - Since 2014
  
  - LSTM보다 적은 수의 파라메터
  
  - Output gate 없음

---

이미지 캡셔닝 - CNN 과 RNN의 결합

- Image embedding (ex: VGGNet)












